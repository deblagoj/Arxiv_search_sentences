{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Arxiv papers that contain specified strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "- List of Arxiv papers\n",
    "- Download of the list\n",
    "- Converting  to TXTs\n",
    "- Analysing the TXTs for containing specific strings\n",
    "\n",
    "Directory structure needs to be created manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import arxiv\n",
    "import time\n",
    "import os\n",
    "from shutil import copyfile\n",
    "\n",
    "\n",
    "# we don't like warnings\n",
    "# you can comment the following 2 lines if you'd like to\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../citations.csv',sep = ';', error_bad_lines=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of Arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list=[]\n",
    "for paper in df['link']:\n",
    "    if \"https://arxiv.org/abs\"  in paper:\n",
    "        index_url = paper.replace('https://arxiv.org/abs/','')\n",
    "        list.append(index_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download paper from Arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterrator \"i\" is set intentionaly to monitor when the connection will break and continue manualy from there\n",
    "# if connection break, just enter range starting from that number\n",
    "for i in range (len(list)):\n",
    "    print(i)\n",
    "    empty_list=[]\n",
    "    empty_list.append(list[i])\n",
    "    search = arxiv.Search(id_list=empty_list)\n",
    "    p = next(search.results())\n",
    "    print(p.title)\n",
    "    p.download_pdf(dirpath=\"../arxiv_papers/pdfs\")\n",
    "    time.sleep(5.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covert PDFs to TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import os\n",
    "\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfparser import PDFParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(\"../arxiv_papers/pdfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(\"../arxiv_papers/pdfs\")\n",
    "for i,f in enumerate(files):\n",
    "    print(f)\n",
    "    output_string = StringIO()\n",
    "    try:\n",
    "        with open('../arxiv_papers/pdfs/'+f, 'rb') as in_file:\n",
    "            \n",
    "            parser = PDFParser(in_file)\n",
    "            doc = PDFDocument(parser)\n",
    "            rsrcmgr = PDFResourceManager()\n",
    "            device = TextConverter(rsrcmgr, output_string, laparams=LAParams())\n",
    "            interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "            for page in PDFPage.create_pages(doc):\n",
    "                interpreter.process_page(page)\n",
    "          \n",
    "            f=f[0:len(f)-3]\n",
    "        with open('../arxiv_papers/txt/'+f+'txt', \"w\") as text_file:\n",
    "            text_file.write(output_string.getvalue())\n",
    "    except:\n",
    "      print(\"An exception occurred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Analyse TXTs for a string\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "KeyStrings =[ 'Who created the dataset', \n",
    "             \"For what purpose was the dataset created\", \n",
    "             \"Is the dataset self-contained\", \n",
    "             \"When will the dataset be distributed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/arxiv_papers/pdfs/1803.09010v7.Datasheets_for_Datasets.txtpdf\n",
      "An exception occurred\n",
      "/arxiv_papers/pdfs/2106.09578v1.Modeling_Worlds_in_Text.txtpdf\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "/arxiv_papers/pdfs/2106.02636v2.MERLOT_Multimodal_Neural_Script_Knowledge_Models.txtpdf\n",
      "An exception occurred\n",
      "/arxiv_papers/pdfs/2106.02787v1.BiToD_A_Bilingual_Multi_Domain_Dataset_For_Task_Oriented_Dialogue_Modeling.txtpdf\n",
      "An exception occurred\n",
      "/arxiv_papers/pdfs/2104.02710v3.The_Multi_Agent_Behavior_Dataset_Mouse_Dyadic_Social_Interactions.txtpdf\n",
      "An exception occurred\n",
      "/arxiv_papers/pdfs/2010.07954v1.Room_Across_Room_Multilingual_Vision_and_Language_Navigation_with_Dense_Spatiotemporal_Grounding.txtpdf\n",
      "An exception occurred\n",
      "/arxiv_papers/pdfs/2106.08261v2.Physion_Evaluating_Physical_Prediction_from_Vision_in_Humans_and_Machines.txtpdf\n",
      "An exception occurred\n",
      "/arxiv_papers/pdfs/2008.02275v5.Aligning_AI_With_Shared_Human_Values.txtpdf\n",
      "An exception occurred\n",
      "/arxiv_papers/pdfs/2103.07532v2.Comprehensive_and_Comprehensible_Data_Catalogs_The_What_Who_Where_When_Why_and_How_of_Metadata_Management.txtpdf\n",
      "An exception occurred\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(\"../arxiv_papers/txt\")\n",
    "for i,f in enumerate(files):\n",
    "    try:\n",
    "        with open(\"../arxiv_papers/txt/\"+f, \"r\") as document:\n",
    "            read_data = document.read()\n",
    "            #print(read_data)\n",
    "            for x in KeyStrings:\n",
    "                if x in read_data:\n",
    "                    print(\"/arxiv_papers/pdfs/\"+f+\"pdf\")\n",
    "                    f=f[0:len(f)-3]\n",
    "                    copyfile(os.getcwd()+\"/arxiv_papers/pdfs/\"+f+\"pdf\", os.getcwd()+\"/arxiv_papers/selected/\"+f+\"pdf\")\n",
    "                    \n",
    "\n",
    "    except:\n",
    "      print(\"An exception occurred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
